{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Neural network implementations are more easily accessible now than ever before, abstracting away complexities like gradients, activation layers, and training algorithms. Building neural networks layer by layer from scratch helped me develop a deeper understanding of the structural capabilities and shortcomings of these models. This project implements modular layers for a scalable <strong>[Convolutional Neural Network](https://www.geeksforgeeks.org/introduction-convolution-neural-network/)</strong> using numpy and train it on the <strong>[Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist)</strong> dataset to perform a simple classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashion MNIST\n",
    "\n",
    "The [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset was modeled on the original [MNIST](http://yann.lecun.com/exdb/mnist/) database of handwritten digits to provide a more challenging image classification task. While Fashion MNIST is also a set of 70k (60k train and 10k test) black and white 28x28 pixel images, the classes are much more abstract than the original MNIST. Each image is an article of clothing belonging to one of 10 classes: \"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", and \"Ankle boot\": \n",
    "\n",
    "![sample](assets/cnn_sample.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries used in this implementation; torcvhision is only used to download the dataset\n",
    "import numpy as np\n",
    "from numpy import logical_and, sum as t_sum\n",
    "from torchvision import datasets\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "traintensors = datasets.FashionMNIST(root=\"./data\", train=True, download=True)\n",
    "testtensors = datasets.FashionMNIST(root=\"./data\", train=False, download=True)\n",
    "\n",
    "# Convert the tensors to numpy arrays\n",
    "trainset = np.array(traintensors.data)\n",
    "trainlabels = np.array(traintensors.targets)\n",
    "testset = np.array(testtensors.data)\n",
    "testlabels = np.array(testtensors.targets)\n",
    "classes = (\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look some images\n",
    "shuffle = trainset[np.random.permutation(len(trainset))]\n",
    "fig, ax = plt.subplots(3, 3)\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        ax[i, j].imshow(shuffle[i * 3 + j], cmap=\"gray\")\n",
    "        ax[i, j].set_title(classes[trainlabels[i * 3 + j]])\n",
    "        ax[i, j].axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Layer\n",
    "\n",
    "![cross-correlate](assets/cnn_cross-correlate.png)\n",
    "\n",
    "The core of the CNN is convlution: odd-numbered square kernels (5x5 in this case) are multiplied elementwise on the image and summed up. Strictly speaking this is [cross-correlation](https://towardsdatascience.com/convolution-vs-cross-correlation-81ec4a0ec253); the only difference in convlution is that the kernel is rotated 180°, as will be seen in the backpropagation algorithm. The kernel is iterated across the image in <strong>strides</strong> (I use stride=1) and are positionally combined to form a 2D array. Notice that since kernels are larger than one pixel, the resulting array will be smaller than the original image. In order to produce arrays of equal size, this implementation <strong>pads</strong> the array with borders of zeroes (border size 2 for the 5x5 kernel), called <strong>full convolution</strong> as opposed to <strong>valid convlution</strong>. The layer is Xavier initialized with weights (represented by kernels) and biases, customizeable by kernel size and number. \n",
    "\n",
    "### Forward\n",
    "\n",
    "The forward portion is straightforward: pad the input matrix according to kernel size and iterate across that matrix to get all regions that need to be cross-correlated with the kernel. Perform the cross correlation by multiplying elementwise (numpy's multiply function does this by default) and then sum up elements on all axes. Since we generally work with more than one kernel and input matrices are often 3D, we can stack kernels into a 4D matrix that can be easily multiplied with the 3D input array. The regions will be multiplied along the first dimension of the kernel array and summed up along the other three dimensions which will generate a 1D vector representing the output of each kernel on the region.\n",
    "\n",
    "### Backpropagation\n",
    "\n",
    "![convolution](assets/cnn_convolution.png)\n",
    "\n",
    "The backpropagation for the convolution layer is much more complicated, especially since an input gradient must also be calculated to backpropagate to lower layers. Terminology for backpropagation may be tricky here: <strong>the input gradient is the gradient of the input matrix during the forward phase. For the first layer, that matrix represents the input image.</strong> The output gradient is the input to the backpropagation function, which for the output layer is the initial gradient calculated with the gold standard label. The bias gradient is easiest to resolve: since it is the base of the output, it should simply be adjusted by the output gradient. To understand backpropgating the kernel weights, consider that each kernel is iterated across the input matrix and apply to all regions equally which means that each region of the gradient should have some effect on the kernel. The kernel gradient is therefore the sum of the product between the output gradient and the previous input matrix for each region of kernel size.\n",
    "\n",
    "The input gradient is where we encounter convolution. Without going into too much mathematical detail, consider that each input element has a different and unequal effect on the output: corner elements will only contribute to the one corner element in the output whereas edges and central elements will contribute to multiple output elements. This same pattern occurs when calculating the derivative with respect to the input elements, since output elements that were not calculated with the input element will have a derivative of 0 with respect to that input element. The key difference is that each output element is affected by the opposite kernel element, which means that the kernel must be rotated 180° (precisely as in convolution) in order to calculate the gradient for the input element. In order to truly keep this pattern, a full convolution must be used, even for models that use valid cross-correlation in the forward portion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer:\n",
    "    def __init__(self, input_shape, kernel_size=5, num_kernels=6, padding=0):\n",
    "        # Get input dimensions\n",
    "        input_depth, input_height, input_width = input_shape\n",
    "        self.d = input_depth\n",
    "        self.h = input_height + kernel_size - 1\n",
    "        self.w = input_width + kernel_size - 1\n",
    "        self.input_shape = input_shape\n",
    "        # Initialize kernels and bias\n",
    "        self.padding = padding\n",
    "        self.num_kernels = num_kernels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.pad_size = kernel_size // 2\n",
    "        self.kernel_shape = (self.num_kernels, self.d, self.kernel_size, self.kernel_size)\n",
    "        self.bias_shape = (self.num_kernels, self.h - self.kernel_size + 1, self.w - self.kernel_size + 1)\n",
    "        # Dividing mimics Xavier Initialization and reduces variance\n",
    "        self.kernels = np.random.randn(*self.kernel_shape) / (self.kernel_size * self.kernel_size)\n",
    "        self.bias = np.random.randn(*self.bias_shape) / (self.h * self.w)\n",
    "    \n",
    "    def iter_regions(self, image):\n",
    "        \"\"\"\n",
    "        Generates all possible (kernel_size x kernel_size) image regions (prepadded)\n",
    "        \"\"\"\n",
    "        for i in range(self.h - self.kernel_size + 1):\n",
    "            for j in range(self.w - self.kernel_size + 1):\n",
    "                im_region = image[:, i:(i + self.kernel_size), j:(j + self.kernel_size)]\n",
    "                yield im_region, i, j\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Pad input, get regions, and perform full cross correlation with kernels\n",
    "        \"\"\"\n",
    "        padded = np.pad(input, ((0,0), (self.pad_size, self.pad_size), (self.pad_size, self.pad_size)), mode=\"constant\", constant_values=self.padding)\n",
    "        self.prev_input = padded # Save for backpropagation\n",
    "        self.output = np.copy(self.bias)\n",
    "        for im_region, i, j in self.iter_regions(padded):\n",
    "            self.output[:, i, j] += np.sum(im_region * self.kernels, axis=(1, 2, 3))\n",
    "        return self.output\n",
    "    \n",
    "    def backprop(self, d_L_d_out, learn_rate):\n",
    "        \"\"\"\n",
    "        Update kernels and bias, and return input gradient\n",
    "        \"\"\"\n",
    "        # Cross correlation for kernel gradient\n",
    "        d_L_d_kernels = np.zeros(self.kernels.shape)\n",
    "        for im_region, i, j in self.iter_regions(self.prev_input):\n",
    "            for f in range(self.num_kernels):\n",
    "                d_L_d_kernels[f] += d_L_d_out[f, i, j] * im_region \n",
    "        # Full convolution for input gradient\n",
    "        d_L_d_input = np.zeros(self.input_shape)\n",
    "        pad_out = np.pad(d_L_d_out, ((0,0), (self.pad_size, self.pad_size), (self.pad_size, self.pad_size)), mode=\"constant\", constant_values=0)\n",
    "        conv_kernels = np.rot90(np.moveaxis(self.kernels, 0, 1), 2, axes=(2, 3))\n",
    "        for im_region2, i, j in self.iter_regions(pad_out):\n",
    "            for d in range(self.d):\n",
    "                d_L_d_input[d, i, j] += np.sum(im_region2 * conv_kernels[d])\n",
    "        # Adjust by learn rate\n",
    "        self.bias -= learn_rate * d_L_d_out\n",
    "        self.kernels -= learn_rate * d_L_d_kernels\n",
    "        return d_L_d_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReLU Activation Layer\n",
    "\n",
    "![relu](assets/cnn_relu.png)\n",
    "\n",
    "At the core of the neural network is the activation function, which is applied to the outputs of the previous layer to introduce nonlinearity. Without activation, stacked layers remain linear and have the same predictive power as a single layer. The downside to the nonlinear function occurs in backpropagation, where certain outputs can result in disappearing gradients breaking the training loop. For this reason, many models prefer using <strong>[ReLU](https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/)</strong> as the activation function for non-terminal layers. ReLU behaves linearly for inputs greater than 0 which means its derivative is 1, preventing disappearing gradients while maintaining nonlinearity. The derivative of ReLU is undefined at 0 conventionally we set it to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    \"\"\"\n",
    "    Simple ReLU activation function\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, input):\n",
    "        self.prev_output = np.maximum(0, input)\n",
    "        return self.prev_output\n",
    "    \n",
    "    def backprop(self, d_L_d_out):\n",
    "        return d_L_d_out * np.int64(self.prev_output > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling Layer\n",
    "\n",
    "![max-pool](assets/cnn_pool.png)\n",
    "\n",
    "Kernels in the convolution layer capture information from neighboring pixels, which means that many elements in the output array contain redundant information. While this is hardly an issue for the 28x28 Fashion MNIST images, one can imagine computation quickly gets out of hand for multilayer networks processing images in the thousands or tens of thousands of pixels. <strong>Pooling</strong> presents a simple solution: run another square array across the output matrix and at each <strong>stride</strong> keep only the max, min, or average value. This implementation uses a 2x2 max pool, but any value will evenly reduce the size of the output while keeping the most important information. The size of the pool should be balanced with the size of the kernel in the convolutional layer but at minimum, each pooling layer reduces the size of the input by a factor of 4.\n",
    "\n",
    "Since no weights are learned, the forward and backpropagation of the pooling layer is simple and deterministic. In the forward pass, the input array is reduced by the method described. In the backpropagation portion, we simply place the gradient values in their respective positions in the input matrix and set all other values to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool:\n",
    "    def __init__(self, pool_size=2):\n",
    "        self.size = pool_size\n",
    "    \n",
    "    def iter_regions(self, image):\n",
    "        \"\"\"\n",
    "        Same as Conv layer, but with stride of pool_size\n",
    "        \"\"\"\n",
    "        _, h, w = image.shape\n",
    "        new_h = h // self.size\n",
    "        new_w = w // self.size\n",
    "        for i in range(new_h):\n",
    "            for j in range(new_w):\n",
    "                im_region = image[:, (i * self.size):(i * self.size + self.size), (j * self.size):(j * self.size + self.size)]\n",
    "                yield im_region, i, j\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Gets max value in each region\n",
    "        \"\"\"\n",
    "        self.prev_input = input\n",
    "        num_kernels, h, w = input.shape\n",
    "        output = np.zeros((num_kernels, h // self.size, w // self.size))\n",
    "        for im_region, i, j in self.iter_regions(input):\n",
    "            output[:, i, j] = np.amax(im_region, axis=(1, 2))\n",
    "        return output\n",
    "    \n",
    "    def backprop(self, d_L_d_out):\n",
    "        \"\"\"\n",
    "        Backpropagates gradient to input\n",
    "        \"\"\"\n",
    "        d_L_d_input = np.zeros(self.prev_input.shape)\n",
    "        for im_region, i, j in self.iter_regions(self.prev_input):\n",
    "            f, h, w = im_region.shape\n",
    "            amax = np.amax(im_region, axis=(1, 2))\n",
    "            for i2 in range(h):\n",
    "                for j2 in range(w):\n",
    "                    for f2 in range(f):\n",
    "                        if im_region[f2, i2, j2] == amax[f2]:\n",
    "                            d_L_d_input[f2, i * self.size + i2, j * self.size + j2] = d_L_d_out[f2, i, j]\n",
    "        return d_L_d_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward Layer\n",
    "\n",
    "![feedforward](assets/cnn_feedforward.png)\n",
    "\n",
    "We have a working system for extracting features from input images now that convolution has been implemented, which leaves only the classification step. For smaller models, a single softmax classification layer as seen below may be sufficient, but generally a full feed forward network is used for prediction. As previously explained, the feedfoward layer collapses the input matrix into a 1 dimensional array (from 14x14x6 to 1176x1 in this exercise), with each element of the array representing a separate feature for the feed forward network. Multiplying with a weight matrix returns an array of the desired size, and an activation layer is used to achieve nonlinearity. The backpropagation is fairly straightforward: the output gradient is multiplied by the previous input to get the weight gradients, the output gradient is the bias gradient, and the input gradient is the weights multiplied by the output gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.randn(input_size, output_size) / input_size\n",
    "        self.bias = np.random.randn(output_size) / output_size\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Multiply by weights and add bias\n",
    "        \"\"\"\n",
    "        self.prev_input_shape = input.shape\n",
    "        input = input.flatten()\n",
    "        self.prev_input = input\n",
    "        self.output = np.dot(input, self.weights) + self.bias\n",
    "        return self.output\n",
    "    \n",
    "    def backprop(self, d_L_d_out, learn_rate):\n",
    "        \"\"\"\n",
    "        Update weights and bias, and return input gradient\n",
    "        \"\"\"\n",
    "        d_out_d_weights = self.prev_input\n",
    "        d_out_d_input = self.weights\n",
    "        d_L_d_weights = d_out_d_weights[np.newaxis].T @ d_L_d_out[np.newaxis]\n",
    "        d_L_d_input = d_out_d_input @ d_L_d_out\n",
    "        self.weights -= learn_rate * d_L_d_weights\n",
    "        self.bias -= learn_rate * d_L_d_out\n",
    "        return d_L_d_input.reshape(self.prev_input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Layer\n",
    "\n",
    "The output layer is the same as in other networks performing classification tasks: a number of features are passed in, multiplied by a weight matrix to get the correct number of outputs and run through a softmax function (or sigmoid for binary classification) to get an output array representing the probability for each class. The only differences between the output and feed forward layers are in the activation function and the backpropagation. Generally, the output layer always uses a sigmoid or softmax activation function since these functions convert unbounded numbers into probabilities. However, since these functions are more prone to vanishing gradient issues, they are almost never used for intermediary layers. I therefore implement the softmax function directly into the output layer, although they can be separated as has been done with the ReLU layer. The backpropagation for the output layer needs to take into account the fact that the gradient is only nonzero for the gold standard class but is otherwise the same as in the feedforward layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def __init__(self, input_len, nodes):\n",
    "        self.weights = np.random.randn(input_len, nodes) / input_len\n",
    "        self.bias = np.random.randn(nodes) / nodes\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Flatten input, matrix multiply with weights, add bias, and get softmax\n",
    "        \"\"\"\n",
    "        # Forward pass\n",
    "        totals = np.dot(input, self.weights) + self.bias\n",
    "        exp = np.exp(totals)\n",
    "        # Saving forward pass for backpropagation\n",
    "        self.prev_input_shape = input.shape\n",
    "        self.prev_input = input\n",
    "        self.prev_totals = totals\n",
    "        return exp / np.sum(exp, axis=0)\n",
    "    \n",
    "    def backprop(self, d_L_d_out, learn_rate):\n",
    "        \"\"\"\n",
    "        Softmax backprop for output layer\n",
    "        \"\"\"\n",
    "        for i, gradient in enumerate(d_L_d_out):\n",
    "            # Only the gradient at the correct class is nonzero\n",
    "            if gradient == 0:\n",
    "                continue \n",
    "            # e^totals\n",
    "            t_exp = np.exp(self.prev_totals)\n",
    "            S = np.sum(t_exp)\n",
    "            # Gradients at i against totals\n",
    "            d_out_d_t = -t_exp[i] * t_exp / (S ** 2)\n",
    "            d_out_d_t[i] = t_exp[i] * (S - t_exp[i]) / (S ** 2)\n",
    "            # Gradients of totals against weights/bias/input\n",
    "            d_t_d_w = self.prev_input\n",
    "            d_t_d_b = 1\n",
    "            d_t_d_inputs = self.weights\n",
    "            # Gradients of loss against totals\n",
    "            d_L_d_t = gradient * d_out_d_t\n",
    "            d_L_d_w = d_t_d_w[np.newaxis].T @ d_L_d_t[np.newaxis]\n",
    "            d_L_d_b = d_L_d_t * d_t_d_b\n",
    "            d_L_d_inputs = d_t_d_inputs @ d_L_d_t\n",
    "            # Update weights and bias\n",
    "            self.weights -= learn_rate * d_L_d_w\n",
    "            self.bias -= learn_rate * d_L_d_b\n",
    "            return d_L_d_inputs.reshape(self.prev_input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Structure\n",
    "\n",
    "This architecture uses all of the layers we've implemented so far. The point of this exercise is to demonstrate the function of each layer using minimal computational resources; it is clear from the structure that removing any layer will sharply decrease performance. However, any arbitrary architecture can be implemented since each layer is modular, demonstrating the power and flexibility of the fully implemented CNN. Conventionally, several convolutional and ReLU layers are stacked before adding a pooling layer and multiple such stacks can be layered before adding the final feed forward and output layers. Experimental results suggest that lower convolutional layers learn basic shapes such as edges whereas higher level layers learn more complex features.\n",
    "\n",
    "The model class and training loop is straightforward since the forward and backward functions have been properly implemented. Although the dataset is in black and white, the layers have been implemented to handle 3D inputs (which would be the case for mulitchannel RGB images). As a result, a preprocess function is needed to handle 2D inputs such as the Fashion MNIST dataset and to adjust the channel dimension for RGB images. RGB images are usually processed as height x width x channel matrices, however, for convenient matrix multiplication the channel matrix needs to be moved up to channel x height x width. Using this implementation, the multiplication done in the convolution layer can be done natively in NumPy instead of utilizing additional for loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN:\n",
    "    \"\"\"\n",
    "    Simple CNN using the layers built above.\n",
    "    Structure:\n",
    "    Input -> Conv -> ReLU -> Conv -> ReLU -> MaxPool -> FeedForward -> ReLU -> Softmax\n",
    "    \"\"\"\n",
    "    def __init__(self, ConvLayer_1, ReLU_1, ConvLayer_2, ReLU_2, MaxPool, FeedForward, ReLU_3, Output):\n",
    "        self.ConvLayer_1 = ConvLayer_1\n",
    "        self.ReLU_1 = ReLU_1\n",
    "        self.ConvLayer_2 = ConvLayer_2\n",
    "        self.ReLU_2 = ReLU_2\n",
    "        self.MaxPool = MaxPool\n",
    "        self.FeedForward = FeedForward\n",
    "        self.ReLU_3 = ReLU_3\n",
    "        self.OutputLayer = Output\n",
    "    \n",
    "    def preprocess(self, data):\n",
    "        \"\"\"\n",
    "        Data generally needs to be reshaped for our purposes\n",
    "        \"\"\"\n",
    "        if len(data.shape) == 3:\n",
    "            data = data[:, np.newaxis, :, :]\n",
    "        elif len(data.shape) == 4 and data.shape[3] == 3:\n",
    "            data = np.moveaxis(data, -1, 1)\n",
    "        return data\n",
    "    \n",
    "    def forward(self, image):\n",
    "        \"\"\"\n",
    "        Forward pass through network, transform image from [0, 255] to [-0.5, 0.5] as standard practice\n",
    "        \"\"\"\n",
    "        input = (image / 255) - 0.5\n",
    "        out = self.ConvLayer_1.forward(input)\n",
    "        out = self.ReLU_1.forward(out)\n",
    "        out = self.ConvLayer_2.forward(out)\n",
    "        out = self.ReLU_2.forward(out)\n",
    "        out = self.MaxPool.forward(out)\n",
    "        out = self.FeedForward.forward(out)\n",
    "        out = self.ReLU_3.forward(out)\n",
    "        out = self.OutputLayer.forward(out)\n",
    "        return out\n",
    "    \n",
    "    def backprop(self, gradient, learn_rate):\n",
    "        \"\"\"\n",
    "        Backpropagation through network\n",
    "        \"\"\"\n",
    "        d_L_d_out = self.OutputLayer.backprop(gradient, learn_rate)\n",
    "        d_L_d_out = self.ReLU_3.backprop(d_L_d_out)\n",
    "        d_L_d_out = self.FeedForward.backprop(d_L_d_out, learn_rate)\n",
    "        d_L_d_out = self.MaxPool.backprop(d_L_d_out)\n",
    "        d_L_d_out = self.ReLU_2.backprop(d_L_d_out)\n",
    "        d_L_d_out = self.ConvLayer_2.backprop(d_L_d_out, learn_rate)\n",
    "        d_L_d_out = self.ReLU_1.backprop(d_L_d_out)\n",
    "        d_L_d_out = self.ConvLayer_1.backprop(d_L_d_out, learn_rate)\n",
    "        return d_L_d_out\n",
    "\n",
    "    def avg_f1_score(self, predicted_labels, true_labels, classes):\n",
    "        \"\"\"\n",
    "        Calculate the f1-score for each class and return the average of it\n",
    "        F1 score is the harmonic mean of precision and recall\n",
    "        Precision is True Positives / All Positives Predictions\n",
    "        Recall is True Positives / All Positive Labelsß\n",
    "        \"\"\"\n",
    "        f1_scores = []\n",
    "        for c in classes:\n",
    "            pred_class = np.array([pred == c for pred in predicted_labels])\n",
    "            true_class = np.array([lab == c for lab in true_labels])\n",
    "            precision = (t_sum(logical_and(pred_class, true_class)) / t_sum(pred_class)) if t_sum(pred_class) else 0\n",
    "            recall = t_sum(logical_and(pred_class, true_class)) / t_sum(true_class)if t_sum(true_class) else 0\n",
    "            f1_scores.append(2 * (precision * recall) / (precision + recall)) if precision and recall else 0\n",
    "        return np.mean(f1_scores)\n",
    "\n",
    "    def predict(self, dataset, true_labels, classes):\n",
    "        \"\"\"\n",
    "        Predict labels for dataset and return f1-score\n",
    "        \"\"\"\n",
    "        preds = []\n",
    "        acc = 0\n",
    "        for im, lab in zip(dataset, true_labels):\n",
    "            preds.append(np.argmax(self.forward(im)))\n",
    "            acc += (preds[-1] == lab)\n",
    "        preds = np.array(preds)\n",
    "        accuracy = acc / len(preds)\n",
    "        f1 = self.avg_f1_score(preds, true_labels, classes)\n",
    "        return accuracy, f1\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        trainset,\n",
    "        trainlabels,\n",
    "        devset,\n",
    "        devlabels,\n",
    "        classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "        epochs=3,\n",
    "        learn_rate=0.005\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Training loop for network\n",
    "        \"\"\"\n",
    "        # Preprocess & generate permutation to shuffle data\n",
    "        trainset = self.preprocess(trainset)\n",
    "        devset = self.preprocess(devset)\n",
    "        permutation = np.random.permutation(len(trainset))\n",
    "        train_data = trainset[permutation]\n",
    "        train_labels = trainlabels[permutation]\n",
    "        # Training loop\n",
    "        print(\"Training...\")\n",
    "        for epoch in range(epochs):\n",
    "            losses = []\n",
    "            for image, label in tqdm(list(zip(train_data, train_labels))):\n",
    "                # Forward pass\n",
    "                out = self.forward(image)\n",
    "                # Calculate loss and gradient\n",
    "                loss = -np.log(out[label])\n",
    "                losses.append(loss)\n",
    "                gradient = np.zeros(10)\n",
    "                gradient[label] = -1 / out[label]\n",
    "                # Backpropagation\n",
    "                self.backprop(gradient, learn_rate)\n",
    "            print(f\"Epoch {epoch + 1}, loss: {np.mean(losses):.3f}\")\n",
    "            print(\"Evaluating dev...\")\n",
    "            acc, f1 = self.predict(devset, devlabels, classes)\n",
    "            print(f\"Dev Accuracy: {acc:.3f}, Dev F1 Score: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN(\n",
    "        ConvLayer(input_shape=(1, 28, 28), kernel_size=5, num_kernels=6, padding=0),\n",
    "        ReLU(),\n",
    "        ConvLayer(input_shape=(6, 28, 28), kernel_size=5, num_kernels=6, padding=0),\n",
    "        ReLU(),\n",
    "        MaxPool(),\n",
    "        FeedForward(6 * 14 * 14, 100),\n",
    "        ReLU(),\n",
    "        Softmax(100, 10)\n",
    ")\n",
    "model.train(trainset[:10000], trainlabels[:10000], testset, testlabels, epochs=3, learn_rate=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Model for Benchmark\n",
    "\n",
    "I implement a Keras model using the exact same architecture as above in order to benchmark performance. Since Keras is an optimized library with widespread adoption, running time is predictably orders of magnitude faster than my implementation. However, my model surprisingly outperforms the Keras model if only slightly, suggesting that the underlying mechanisms in both implementations are the same. I achieve an F1 = 0.890 training 3 epochs on the entire dataset (taking roughly half an hour per epoch), which is significantly lower than the state of the art of roughly 0.97, but my model uses a bare bones architecture. With enough time and computation, a much larger structure using the same layers could potentially achieve comparable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers.legacy import SGD\n",
    "\n",
    "train_images = (trainset / 255) - 0.5\n",
    "test_images = (testset / 255) - 0.5\n",
    "\n",
    "train_images = np.expand_dims(train_images, axis=3)\n",
    "test_images = np.expand_dims(test_images, axis=3)\n",
    "\n",
    "model = Sequential([\n",
    "  Conv2D(6, 5, padding=\"same\", input_shape=(28, 28, 1), use_bias=True, activation='relu'),\n",
    "  Conv2D(6, 5, padding=\"same\", input_shape=(28, 28, 6), use_bias=True, activation='relu'),\n",
    "  MaxPooling2D(pool_size=2),\n",
    "  Flatten(),\n",
    "  Dense(100, activation='relu'),\n",
    "  Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(SGD(learning_rate=.005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "  train_images,\n",
    "  to_categorical(trainlabels),\n",
    "  batch_size=1,\n",
    "  epochs=3,\n",
    "  validation_data=(test_images, to_categorical(testlabels)),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLPytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
