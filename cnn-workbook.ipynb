{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of Convolutional Neural Networks\n",
    "\n",
    "Neural networks can generally be understood through three layers: the input, hidden, and output layers. The input layer takes some structured data and processes it for the hidden layer. The hidden layer consecutively applies learned weights and non-linear activation fucntions to the data before passing to the output layer. The output layer uses weights and an activation function to return the number of outputs required by the task. For image classification, this will be a vector whose values correspond to the probability that the input image belongs to each class (the argmax of the vector is therefore the classification we're looking for). \n",
    "\n",
    "[Feed Forward Networks (FNN)](https://www.geeksforgeeks.org/understanding-multi-layer-feed-forward-networks/) is a foundational neural network that perfectly fit this description, simply taking a one dimensional vector (in this case the individual pixels of an image) as input and passing it through weights and activation functions. In computer vision, FNN's are far outclassed by CNN's, which are much better at modelling image data by making stronger assumptions. The core assumption made by CNN's is that information captured by neighboring pixels are highly correlated, which means that 1. features can be captured by looking at regions of neighboring pixels and 2. not all pixels are necessary for image classification. A square 28 pixel RGB image will be transformed into a 2352x1 array by the FNN's input layer, so the network cannot infer that the first three elements represent the same pixel or that the next three elements represent a neighboring pixel. \n",
    "\n",
    "[Convolutional Neural Networks (CNN)](https://www.geeksforgeeks.org/introduction-convolution-neural-network/) capture image structure using <strong>convolution</strong>, which involves sliding a <strong>kernel</strong> across the input matrix to capture some feature. Kernels are square matrices of learned weights which in theory should highlight some part of the input image that is pertinent to the classification task. Since convolutions produce redundant information, the resulting matrix is put through a <strong>pooling</strong> layer which only preserves the most significant element in every stride. For example, the 2x2 Max Pool used in this immplementation only keeps the maximum element in every four, producing an output matrix half the width and height of the original. This resulting matrix is then passed through a feed forward layer which is essentially just an FNN. However, the previous steps should have both highlighted important data in the image and discarded redundant elements, allowing the weights of the feed forward layer to more optimally learn the classification features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (1.26.3)\n",
      "Requirement already satisfied: torchvision in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (0.16.2)\n",
      "Requirement already satisfied: torch in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (2.1.2)\n",
      "Requirement already satisfied: tqdm in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (4.66.1)\n",
      "Requirement already satisfied: matplotlib in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (3.8.2)\n",
      "Requirement already satisfied: tensorflow in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (2.15.0)\n",
      "Requirement already satisfied: requests in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from torchvision->-r requirements.txt (line 2)) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from torchvision->-r requirements.txt (line 2)) (10.2.0)\n",
      "Requirement already satisfied: filelock in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (2023.12.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (2.8.2)\n",
      "Requirement already satisfied: tensorflow-macos==2.15.0 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 6)) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 6)) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 6)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 6)) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 6)) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 6)) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 6)) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 6)) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 6)) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 6)) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 6)) (4.23.4)\n",
      "Requirement already satisfied: setuptools in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 6)) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 6)) (2.4.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 6)) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 6)) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 6)) (1.60.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 6)) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 6)) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 6)) (2.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from jinja2->torch->-r requirements.txt (line 3)) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from requests->torchvision->-r requirements.txt (line 2)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from requests->torchvision->-r requirements.txt (line 2)) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from requests->torchvision->-r requirements.txt (line 2)) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from requests->torchvision->-r requirements.txt (line 2)) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from sympy->torch->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 6)) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 6)) (2.26.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 6)) (3.5.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 6)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 6)) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 6)) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 6)) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 6)) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 6)) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 6)) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/alvinchen/anaconda3/envs/cnn/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow->-r requirements.txt (line 6)) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fashion MNIST\n",
    "\n",
    "The [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset was modeled on the original [MNIST](http://yann.lecun.com/exdb/mnist/) database of handwritten digits to provide a more challenging image classification task. While Fashion MNIST is also a set of 70k (60k train and 10k test) black and white 28x28 pixel images, the classes are much more abstract than the original MNIST. Each image is an article of clothing belonging to one of 10 classes: \"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", and \"Ankle boot\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries used in this implementation; torcvhision is only used to download the dataset\n",
    "import numpy as np\n",
    "from numpy import logical_and, sum as t_sum\n",
    "from torchvision import datasets\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "traintensors = datasets.FashionMNIST(root=\"./data\", train=True, download=True)\n",
    "testtensors = datasets.FashionMNIST(root=\"./data\", train=False, download=True)\n",
    "\n",
    "# Convert the tensors to numpy arrays\n",
    "trainset = np.array(traintensors.data)\n",
    "trainlabels = np.array(traintensors.targets)\n",
    "testset = np.array(testtensors.data)\n",
    "testlabels = np.array(testtensors.targets)\n",
    "classes = (\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\")\n",
    "\n",
    "# Take a look at the data\n",
    "for i in range(9):\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    plt.imshow(trainset[i], cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Layer\n",
    "\n",
    "The core of CNN's relies on convlution: a 5x5 <strong>kernel</strong> (other odd-numbered square matrices are also possible) that is multiplied elementwise on the image and summed up. The kernel is iterated across the image in <strong>strides</strong> and are positionally combined to form a 2D array. However, since kernels are larger than one pixel, the resulting array will be smaller than the original image. In order to produce resulting arrays of the correct size, we <strong>pad</strong> the array with borders of zeroes. For a 5x5 kernel, the border must be size 2.\n",
    "\n",
    "#### Convlution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer:\n",
    "    def __init__(self, input_shape, kernel_size=5, num_kernels=6, padding=0):\n",
    "        # Get input dimensions\n",
    "        input_depth, input_height, input_width = input_shape\n",
    "        self.d = input_depth\n",
    "        self.h = input_height + kernel_size - 1\n",
    "        self.w = input_width + kernel_size - 1\n",
    "        self.input_shape = input_shape\n",
    "        # Initialize kernels and bias\n",
    "        self.padding = padding\n",
    "        self.num_kernels = num_kernels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.pad_size = kernel_size // 2\n",
    "        self.kernel_shape = (self.num_kernels, self.d, self.kernel_size, self.kernel_size)\n",
    "        self.bias_shape = (self.num_kernels, self.h - self.kernel_size + 1, self.w - self.kernel_size + 1)\n",
    "        # Dividing mimics Xavier Initialization and reduces variance\n",
    "        self.kernels = np.random.randn(*self.kernel_shape) / (self.kernel_size * self.kernel_size)\n",
    "        self.bias = np.random.randn(*self.bias_shape) / (self.h * self.w)\n",
    "    \n",
    "    def iter_regions(self, image):\n",
    "        \"\"\"\n",
    "        Generates all possible (kernel_size x kernel_size) image regions (prepadded)\n",
    "        \"\"\"\n",
    "        for i in range(self.h - self.kernel_size + 1):\n",
    "            for j in range(self.w - self.kernel_size + 1):\n",
    "                im_region = image[:, i:(i + self.kernel_size), j:(j + self.kernel_size)]\n",
    "                yield im_region, i, j\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Pad input, get regions, and perform full cross correlation with kernels\n",
    "        \"\"\"\n",
    "        padded = np.pad(input, ((0,0), (self.pad_size, self.pad_size), (self.pad_size, self.pad_size)), mode=\"constant\", constant_values=self.padding)\n",
    "        self.prev_input = padded # Save for backpropagation\n",
    "        self.output = np.copy(self.bias)\n",
    "        for im_region, i, j in self.iter_regions(padded):\n",
    "            self.output[:, i, j] += np.sum(im_region * self.kernels, axis=(1, 2, 3))\n",
    "        return self.output\n",
    "    \n",
    "    def backprop(self, d_L_d_out, learn_rate):\n",
    "        \"\"\"\n",
    "        Update kernels and bias, and return input gradient\n",
    "        \"\"\"\n",
    "        # Cross correlation for kernel gradient\n",
    "        d_L_d_kernels = np.zeros(self.kernels.shape)\n",
    "        for im_region, i, j in self.iter_regions(self.prev_input):\n",
    "            for f in range(self.num_kernels):\n",
    "                d_L_d_kernels[f] += d_L_d_out[f, i, j] * im_region \n",
    "        # Full convolution for input gradient\n",
    "        d_L_d_input = np.zeros(self.input_shape)\n",
    "        pad_out = np.pad(d_L_d_out, ((0,0), (self.pad_size, self.pad_size), (self.pad_size, self.pad_size)), mode=\"constant\", constant_values=0)\n",
    "        conv_kernels = np.rot90(np.moveaxis(self.kernels, 0, 1), 2, axes=(2, 3))\n",
    "        for im_region2, i, j in self.iter_regions(pad_out):\n",
    "            for d in range(self.d):\n",
    "                d_L_d_input[d, i, j] += np.sum(im_region2 * conv_kernels[d])\n",
    "        # Adjust by learn rate\n",
    "        self.bias -= learn_rate * d_L_d_out\n",
    "        self.kernels -= learn_rate * d_L_d_kernels\n",
    "        return d_L_d_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    \"\"\"\n",
    "    Simple ReLU activation function\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, input):\n",
    "        self.prev_output = np.maximum(0, input)\n",
    "        return self.prev_output\n",
    "    \n",
    "    def backprop(self, d_L_d_out):\n",
    "        return d_L_d_out * np.int64(self.prev_output > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Pooling Layer\n",
    "Since convolutions capture information from neighboring pixels, many elements in the output array are redundant. <strong>Pooling</strong> presents a simple solution: run another square array across the output matrix and at each <strong>stride</strong> keep only the max, min, or average value. In this implementation I use the max value, but any value will evenly reduce the size of the output while keeping the most important information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool:\n",
    "    def __init__(self, pool_size=2):\n",
    "        self.size = pool_size\n",
    "    \n",
    "    def iter_regions(self, image):\n",
    "        \"\"\"\n",
    "        Same as Conv layer, but with stride of pool_size\n",
    "        \"\"\"\n",
    "        _, h, w = image.shape\n",
    "        new_h = h // self.size\n",
    "        new_w = w // self.size\n",
    "        for i in range(new_h):\n",
    "            for j in range(new_w):\n",
    "                im_region = image[:, (i * self.size):(i * self.size + self.size), (j * self.size):(j * self.size + self.size)]\n",
    "                yield im_region, i, j\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Gets max value in each region\n",
    "        \"\"\"\n",
    "        self.prev_input = input\n",
    "        num_kernels, h, w = input.shape\n",
    "        output = np.zeros((num_kernels, h // self.size, w // self.size))\n",
    "        for im_region, i, j in self.iter_regions(input):\n",
    "            output[:, i, j] = np.amax(im_region, axis=(1, 2))\n",
    "        return output\n",
    "    \n",
    "    def backprop(self, d_L_d_out):\n",
    "        \"\"\"\n",
    "        Backpropagates gradient to input\n",
    "        \"\"\"\n",
    "        d_L_d_input = np.zeros(self.prev_input.shape)\n",
    "        for im_region, i, j in self.iter_regions(self.prev_input):\n",
    "            f, h, w = im_region.shape\n",
    "            amax = np.amax(im_region, axis=(1, 2))\n",
    "            for i2 in range(h):\n",
    "                for j2 in range(w):\n",
    "                    for f2 in range(f):\n",
    "                        if im_region[f2, i2, j2] == amax[f2]:\n",
    "                            d_L_d_input[f2, i * self.size + i2, j * self.size + j2] = d_L_d_out[f2, i, j]\n",
    "        return d_L_d_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Output:\n",
    "    def __init__(self, input_len, nodes):\n",
    "        self.weights = np.random.randn(input_len, nodes) / input_len\n",
    "        self.bias = np.zeros(nodes)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Flatten input, matrix multiply with weights, add bias, and get softmax\n",
    "        \"\"\"\n",
    "        # Forward pass\n",
    "        flat = input.flatten()\n",
    "        totals = np.dot(flat, self.weights) + self.bias\n",
    "        exp = np.exp(totals)\n",
    "        # Saving forward pass for backpropagation\n",
    "        self.prev_input_shape = input.shape\n",
    "        self.prev_input = flat\n",
    "        self.prev_totals = totals\n",
    "        return exp / np.sum(exp, axis=0)\n",
    "    \n",
    "    def backprop(self, d_L_d_out, learn_rate):\n",
    "        \"\"\"\n",
    "        Softmax backprop for output layer\n",
    "        \"\"\"\n",
    "        for i, gradient in enumerate(d_L_d_out):\n",
    "            # Only the gradient at the correct class is nonzero\n",
    "            if gradient == 0:\n",
    "                continue \n",
    "            # e^totals\n",
    "            t_exp = np.exp(self.prev_totals)\n",
    "            S = np.sum(t_exp)\n",
    "            # Gradients at i against totals\n",
    "            d_out_d_t = -t_exp[i] * t_exp / (S ** 2)\n",
    "            d_out_d_t[i] = t_exp[i] * (S - t_exp[i]) / (S ** 2)\n",
    "            # Gradients of totals against weights/bias/input\n",
    "            d_t_d_w = self.prev_input\n",
    "            d_t_d_b = 1\n",
    "            d_t_d_inputs = self.weights\n",
    "            # Gradients of loss against totals\n",
    "            d_L_d_t = gradient * d_out_d_t\n",
    "            d_L_d_w = d_t_d_w[np.newaxis].T @ d_L_d_t[np.newaxis]\n",
    "            d_L_d_b = d_L_d_t * d_t_d_b\n",
    "            d_L_d_inputs = d_t_d_inputs @ d_L_d_t\n",
    "            # Update weights and bias\n",
    "            self.weights -= learn_rate * d_L_d_w\n",
    "            self.bias -= learn_rate * d_L_d_b\n",
    "            return d_L_d_inputs.reshape(self.prev_input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN:\n",
    "    \"\"\"\n",
    "    Simple CNN using the layers built above.\n",
    "    Architecture:\n",
    "    Input -> Conv -> ReLU -> Conv -> ReLU -> MaxPool -> Dense -> Dense -> Output\n",
    "    \"\"\"\n",
    "    def __init__(self, ConvLayer_1, ReLU_1, ConvLayer_2, ReLU_2, MaxPool, Output):\n",
    "        self.ConvLayer_1 = ConvLayer_1\n",
    "        self.ReLU_1 = ReLU_1\n",
    "        self.ConvLayer_2 = ConvLayer_2\n",
    "        self.ReLU_2 = ReLU_2\n",
    "        self.MaxPool = MaxPool\n",
    "        self.OutputLayer = Output\n",
    "    \n",
    "    def preprocess(self, data):\n",
    "        \"\"\"\n",
    "        Data generally needs to be reshaped for our purposes\n",
    "        \"\"\"\n",
    "        if len(data.shape) == 3:\n",
    "            data = data[:, np.newaxis, :, :]\n",
    "        elif len(data.shape) == 4 and data.shape[3] == 3:\n",
    "            data = np.moveaxis(data, -1, 1)\n",
    "        return data\n",
    "    \n",
    "    def forward(self, image):\n",
    "        \"\"\"\n",
    "        Forward pass through network, transform image from [0, 255] to [-0.5, 0.5] as standard practice\n",
    "        \"\"\"\n",
    "        input = (image / 255) - 0.5\n",
    "        out = self.ConvLayer_1.forward(input)\n",
    "        out = self.ReLU_1.forward(out)\n",
    "        out = self.ConvLayer_2.forward(out)\n",
    "        out = self.ReLU_2.forward(out)\n",
    "        out = self.MaxPool.forward(out)\n",
    "        out = self.OutputLayer.forward(out)\n",
    "        return out\n",
    "    \n",
    "    def backprop(self, gradient, learn_rate):\n",
    "        \"\"\"\n",
    "        Backpropagation through network\n",
    "        \"\"\"\n",
    "        d_L_d_out = self.OutputLayer.backprop(gradient, learn_rate)\n",
    "        d_L_d_out = self.MaxPool.backprop(d_L_d_out)\n",
    "        d_L_d_out = self.ReLU_2.backprop(d_L_d_out)\n",
    "        d_L_d_out = self.ConvLayer_2.backprop(d_L_d_out, learn_rate)\n",
    "        d_L_d_out = self.ReLU_1.backprop(d_L_d_out)\n",
    "        d_L_d_out = self.ConvLayer_1.backprop(d_L_d_out, learn_rate)\n",
    "        return d_L_d_out\n",
    "\n",
    "    def avg_f1_score(self, predicted_labels, true_labels, classes):\n",
    "        \"\"\"\n",
    "        Calculate the f1-score for each class and return the average of it\n",
    "        F1 score is the harmonic mean of precision and recall\n",
    "        Precision is True Positives / All Positives Predictions\n",
    "        Recall is True Positives / All Positive Labelsß\n",
    "        \"\"\"\n",
    "        f1_scores = []\n",
    "        for c in classes:\n",
    "            pred_class = np.array([pred == c for pred in predicted_labels])\n",
    "            true_class = np.array([lab == c for lab in true_labels])\n",
    "            precision = (t_sum(logical_and(pred_class, true_class)) / t_sum(pred_class)) if t_sum(pred_class) else 0\n",
    "            recall = t_sum(logical_and(pred_class, true_class)) / t_sum(true_class)if t_sum(true_class) else 0\n",
    "            f1_scores.append(2 * (precision * recall) / (precision + recall)) if precision and recall else 0\n",
    "        return np.mean(f1_scores)\n",
    "\n",
    "    def predict(self, dataset, true_labels, classes):\n",
    "        \"\"\"\n",
    "        Predict labels for dataset and return f1-score\n",
    "        \"\"\"\n",
    "        preds = []\n",
    "        acc = 0\n",
    "        for im, lab in zip(dataset, true_labels):\n",
    "            preds.append(np.argmax(self.forward(im)))\n",
    "            acc += (preds[-1] == lab)\n",
    "        preds = np.array(preds)\n",
    "        accuracy = acc / len(preds)\n",
    "        f1 = self.avg_f1_score(preds, true_labels, classes)\n",
    "        return accuracy, f1\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        trainset,\n",
    "        trainlabels,\n",
    "        devset,\n",
    "        devlabels,\n",
    "        classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "        epochs=3,\n",
    "        learn_rate=0.005\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Training loop for network\n",
    "        \"\"\"\n",
    "        # Preprocess & generate permutation to shuffle data\n",
    "        trainset = self.preprocess(trainset)\n",
    "        devset = self.preprocess(devset)\n",
    "        permutation = np.random.permutation(len(trainset))\n",
    "        train_data = trainset[permutation]\n",
    "        train_labels = trainlabels[permutation]\n",
    "        # Training loop\n",
    "        print(\"Training...\")\n",
    "        for epoch in range(epochs):\n",
    "            losses = []\n",
    "            for image, label in tqdm(list(zip(train_data, train_labels))):\n",
    "                # Forward pass\n",
    "                out = self.forward(image)\n",
    "                # Calculate loss and gradient\n",
    "                loss = -np.log(out[label])\n",
    "                losses.append(loss)\n",
    "                gradient = np.zeros(10)\n",
    "                gradient[label] = -1 / out[label]\n",
    "                # Backpropagation\n",
    "                self.backprop(gradient, learn_rate)\n",
    "            print(f\"Epoch {epoch + 1}, loss: {np.mean(losses):.3f}\")\n",
    "            print(\"Evaluating dev...\")\n",
    "            acc, f1 = self.predict(devset, devlabels, classes)\n",
    "            print(f\"Dev Accuracy: {acc:.3f}, Dev F1 Score: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efda2b35a45c46288e3902e63c863d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss: 0.467\n",
      "Evaluating dev...\n",
      "Dev Accuracy: 0.873, Dev F1 Score: 0.870\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a376d4e4bf08438c9ee4c9c8e256d60b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, loss: 0.320\n",
      "Evaluating dev...\n",
      "Dev Accuracy: 0.888, Dev F1 Score: 0.886\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fac22f658db44cf9e5ba1f6b436d5c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, loss: 0.285\n",
      "Evaluating dev...\n",
      "Dev Accuracy: 0.891, Dev F1 Score: 0.890\n"
     ]
    }
   ],
   "source": [
    "model = SimpleCNN(\n",
    "        ConvLayer(input_shape=(1, 28, 28), kernel_size=5, num_kernels=6, padding=0),\n",
    "        ReLU(),\n",
    "        ConvLayer(input_shape=(6, 28, 28), kernel_size=5, num_kernels=6, padding=0),\n",
    "        ReLU(),\n",
    "        MaxPool(),\n",
    "        Output(6 * 14 * 14, 10)\n",
    ")\n",
    "model.train(trainset, trainlabels, testset, testlabels, epochs=3, learn_rate=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 55s 910us/step - loss: 0.4376 - accuracy: 0.8462 - val_loss: 0.3553 - val_accuracy: 0.8742\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 55s 919us/step - loss: 0.3132 - accuracy: 0.8885 - val_loss: 0.3206 - val_accuracy: 0.8867\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 54s 908us/step - loss: 0.2835 - accuracy: 0.8983 - val_loss: 0.3188 - val_accuracy: 0.8872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2b0c4f3a0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers.legacy import SGD\n",
    "\n",
    "train_images = (trainset / 255) - 0.5\n",
    "test_images = (testset / 255) - 0.5\n",
    "\n",
    "train_images = np.expand_dims(train_images, axis=3)\n",
    "test_images = np.expand_dims(test_images, axis=3)\n",
    "\n",
    "model = Sequential([\n",
    "  Conv2D(6, 5, padding=\"same\", input_shape=(28, 28, 1), use_bias=True, activation='relu'),\n",
    "  Conv2D(6, 5, padding=\"same\", input_shape=(28, 28, 6), use_bias=True, activation='relu'),\n",
    "  MaxPooling2D(pool_size=2),\n",
    "  Flatten(),\n",
    "  Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(SGD(learning_rate=.005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "  train_images,\n",
    "  to_categorical(trainlabels),\n",
    "  batch_size=1,\n",
    "  epochs=3,\n",
    "  validation_data=(test_images, to_categorical(testlabels)),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLPytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
